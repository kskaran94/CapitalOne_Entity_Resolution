{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import distance\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import copy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(data_1, data_2, data_col, combined_col):\n",
    "\n",
    "    # Creating graph and nodes from dataset\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for k in range(len(data_col)):\n",
    "        if data_1.columns[k] in combined_col:\n",
    "            G.add_nodes_from(data_1[data_1.columns[k]], t = \"combined_col\")\n",
    "        else:\n",
    "            G.add_nodes_from(data_1[data_1.columns[k]], t = data_col[k])\n",
    "        if data_2.columns[k] in combined_col:\n",
    "            G.add_nodes_from(data_2[data_2.columns[k]], t = \"combined_col\")\n",
    "        else:\n",
    "            G.add_nodes_from(data_2[data_2.columns[k]], t = data_col[k])\n",
    "\n",
    "    # Creating edges\n",
    "    for i in range(len(data_1)):\n",
    "        for k in combined_col:\n",
    "            if k in data_1.columns:\n",
    "                G.add_edge(data_1.id[i], data_1[k][i])\n",
    "\n",
    "    for i in range(len(data_2)):\n",
    "        for k in combined_col:\n",
    "            if k in data_2.columns:\n",
    "                G.add_edge(data_2.id[i], data_2[k][i])\n",
    "\n",
    "    k_type = [i for i in data_col if i not in combined_col]\n",
    "    if len(combined_col) > 0:\n",
    "        k_type.append(\"combined_col\")\n",
    "    return G, k_type\n",
    "\n",
    "# Importing data\n",
    "\n",
    "path = '../Data/Amazon-GoogleProducts/'\n",
    "data_1 = pd.read_csv(path + 'Amazon.csv', encoding = \"latin\")\n",
    "data_2 = pd.read_csv(path + 'GoogleProducts.csv', encoding = \"latin\")\n",
    "\n",
    "# Converting all the data to string\n",
    "for col in data_1.columns:\n",
    "    data_1[col] = data_1[col].apply(str)\n",
    "for col in data_2.columns:\n",
    "    data_2[col] = data_2[col].apply(str)\n",
    "\n",
    "# Defining k_type and columns to be combined into one type\n",
    "data_col = [\"id\", \"title\", \"description\"]\n",
    "word = [\"title\", \"name\", \"description\"]\n",
    "\n",
    "G, k_type = createGraph(data_1, data_2, data_col, word)\n",
    "G.remove_node(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJaccardSim(G, k_type):\n",
    "    CN_sim = []\n",
    "    V = []\n",
    "    for i in k_type:\n",
    "        # to maintain the order of nodes, so that nodes in similarity matrix can be mapped\n",
    "        temp = {'nodes':[], 'name':{}, 'position':{}}\n",
    "        \n",
    "        # extract the node values\n",
    "        nodes = [x for x,y in G.nodes(data=True) if y['t'] == i]\n",
    "        temp['nodes'] = nodes\n",
    "        for x in range(len(nodes)):\n",
    "            temp['name'][x] = nodes[x]\n",
    "            temp['position'][nodes[x]] = x\n",
    "        V.append(temp)\n",
    "        n_t = len(nodes)\n",
    "        \n",
    "        # Similarity between the t-type nodes\n",
    "        sim_t = np.zeros((n_t, n_t))\n",
    "        for x in range(n_t):\n",
    "            for y in range(n_t):\n",
    "                sim_t[x][y] = 1 - distance.jaccard(nodes[x], nodes[y])\n",
    "        \n",
    "        # CN_sim has similarity matrices for all the k-type nodes\t\n",
    "        CN_sim.append(sim_t)\n",
    "    return CN_sim, V\n",
    "\n",
    "\n",
    "CN_sim, V = createJaccardSim(G, k_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createTheGttMatrix(G,V):\n",
    "    Gtt = OrderedDict()\n",
    "    for i in range(len(V)):\n",
    "        for j in range(i+1,len(V)):\n",
    "            subgraph = G.subgraph(V[i]['nodes'] + V[j]['nodes'])\n",
    "            G_t_t_dash = np.zeros((len(V[i]['nodes']), len(V[j]['nodes'])))\n",
    "            for edge in subgraph.edges():\n",
    "                G_t_t_dash[V[i]['position'][edge[0]], V[j]['position'][edge[1]]] = 1\n",
    "            \n",
    "            Gtt[(i,j)]=G_t_t_dash\n",
    "    return Gtt\n",
    "\n",
    "Gtt = createTheGttMatrix(G,V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSuperNodes(V):\n",
    "    number_super_nodes =[]\n",
    "    for v in V:\n",
    "        number_super_nodes.append(int(math.sqrt(len(v['name']))))\n",
    "    \n",
    "    return number_super_nodes\n",
    "\n",
    "\n",
    "number_super_nodes = calcSuperNodes(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 89]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_super_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeMapping(sim, p):\n",
    "    C = []\n",
    "    for i in range(len(sim)):\n",
    "        # C_t is a mapping from all the nodes of t-type to its t-type supernode\n",
    "        C_t = np.zeros((sim[i].shape[0], p[i]))\n",
    "        for j in range(sim[i].shape[0]):\n",
    "            # Randomly maps the t-type node to a t-type supernode\n",
    "            C_t[j]=np.random.dirichlet(np.ones(p[i]),size=1)[0]\n",
    "            #C_t[j, np.random.randint(low = 0, high = p[i])] = 1\n",
    "        C.append(C_t)\n",
    "    return C\n",
    "\n",
    "C = initializeMapping(CN_sim, number_super_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(np.argmax(C[0], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "def createSummaryGraph(G, C, V, k_type):\n",
    "    SG = copy.deepcopy(G)\n",
    "    S = []\n",
    "    \n",
    "    for i in range(len(C)):\n",
    "        S_t = {'super_nodes':defaultdict(list), 'name':{}, 'position':{}}\n",
    "        for j in range(C[i].shape[0]):\n",
    "            ind = list(C[i][j]).index(max(C[i][j]))\n",
    "            S_t['super_nodes'][ind].append(V[i]['name'][j])\n",
    "        \n",
    "        for k,v in S_t['super_nodes'].items():\n",
    "            S_t['name'][k]=v[0]\n",
    "            S_t['position'][v[0]]=k\n",
    "            for j in range(1,len(v)):\n",
    "                SG = nx.contracted_nodes(SG, v[0], v[j])\n",
    "                \n",
    "        S.append(S_t)\n",
    "            \n",
    "    return SG, S\n",
    "\n",
    "SG, S = createSummaryGraph(G, C, V, k_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheSuperLinkMatrix(S):\n",
    "    L = OrderedDict()\n",
    "    for i in range(len(S)):\n",
    "        S_t = S[i]\n",
    "        for j in range(i+1,len(S)):\n",
    "            S_t_dash = S[j]\n",
    "            L_t_t_dash = {i:list(S_t['position'].keys()),\n",
    "                          j:list(S_t_dash['position'].keys()),\n",
    "                          'adj_matrix':np.zeros((len(S_t['super_nodes']), len(S_t_dash['super_nodes'])))}\n",
    "            for k in range(0, len(S_t['super_nodes'])):\n",
    "                L_t_t_dash['adj_matrix'][k]=np.random.dirichlet(np.ones(len(S_t_dash['super_nodes'])),size=1)[0]\n",
    "            \n",
    "            L[(i,j)] = L_t_t_dash\n",
    "            \n",
    "    return L\n",
    "\n",
    "\n",
    "L = createTheSuperLinkMatrix(S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_backup = copy.deepcopy(C)\n",
    "L_backup = copy.deepcopy(L)\n",
    "S_backup = copy.deepcopy(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = C_backup\n",
    "L = L_backup\n",
    "S = S_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDiagonalMatrix(sim):\n",
    "    D=[]\n",
    "    for i in range(0,len(sim)):\n",
    "        D.append(np.diag(np.sum(sim[i],axis=1)))\n",
    "    \n",
    "    return D\n",
    "\n",
    "D = calcDiagonalMatrix(CN_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateC(G, V, C, L, sim, D):\n",
    "    for i in range(len(C)):\n",
    "        C_t = C[i]\n",
    "        D_t = D[i]\n",
    "        sum1 = np.zeros(C_t.shape)\n",
    "        sum2 = np.zeros(C_t.shape)\n",
    "        for j in range(i+1, len(C)):\n",
    "            C_t_dash = C[j]\n",
    "            G_t_t_dash = Gtt[(i,j)]\n",
    "            L_t_t_dash = L[(i,j)]['adj_matrix']\n",
    "            temp1 = np.dot(C_t_dash, L_t_t_dash.transpose())\n",
    "            sum1 += np.dot(G_t_t_dash, temp1)\n",
    "            sum2 += np.dot(C_t, np.dot(L_t_t_dash, np.dot(C_t_dash.transpose(), temp1)))\n",
    "        sum1 += np.matmul(sim[i], C_t)\n",
    "        sum2 += np.matmul(D_t, C_t)\n",
    "        if i >=1:\n",
    "            C[i] = np.multiply(C_t, np.sqrt(np.divide(sum1, sum2)))\n",
    "        for j in range(0,len(C[i])):\n",
    "            C[i][j] = C[i][j]/sum(C[i][j])\n",
    "    return C\n",
    "\n",
    "def updateL(G, V, C, L):\n",
    "    for i in range(len(C)):\n",
    "        C_t = C[i]\n",
    "        for j in range(i+1, len(C)):\n",
    "            L_t_t_dash = L[(i,j)]['adj_matrix']\n",
    "            C_t_dash = C[j]\n",
    "            G_t_t_dash = Gtt[(i,j)]\n",
    "            temp1 = np.dot(C_t.transpose(), np.dot(G_t_t_dash, C_t_dash))\n",
    "            temp2 = np.dot(L_t_t_dash, np.dot(C_t_dash.transpose(), C_t_dash))\n",
    "            temp3 = np.dot(C_t.transpose(), np.dot(C_t, temp2))\n",
    "            L[(i,j)]['adj_matrix'] = np.multiply(L_t_t_dash, np.sqrt(np.divide(temp1, temp3)))\n",
    "            for k in range(0,len(L[(i,j)]['adj_matrix'])):\n",
    "                L[(i,j)]['adj_matrix'][k] = L[(i,j)]['adj_matrix'][k]/sum(L[(i,j)]['adj_matrix'][k])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeObjectiveFunction(C, L, V, CN_sim, G):\n",
    "    k_type = len(C)\n",
    "    first_term, second_term = 0, 0\n",
    "    for type_ in range(k_type):\n",
    "        sim_t = CN_sim[type_]\n",
    "        C_t = C[type_]\n",
    "        n_t = len(sim_t)#n_t: number of vertices in the type\n",
    "\n",
    "        for i in range(n_t):\n",
    "            for j in range(i):\n",
    "                first_term += sim_t[i][j]*np.sum((C_t[i] - C_t[j])**2)\n",
    "\n",
    "    for t in range(k_type):\n",
    "        for t_dash in range(t+1,k_type):\n",
    "            G_t_t_dash = Gtt[(t,t_dash)]\n",
    "            temp1 = np.matmul(L[(t, t_dash)]['adj_matrix'],C[t_dash].transpose())\n",
    "            temp2 = np.matmul(C[t], temp1)\n",
    "\n",
    "            second_term += np.sum((G_t_t_dash - temp2)**2)\n",
    "\n",
    "    objective = first_term + second_term\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle CN_sim and V\n",
    "import pickle\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('sim.pickle', 'wb') as handle:\n",
    "    pickle.dump(CN_sim, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('vertex.pickle', 'wb') as handle:\n",
    "    pickle.dump(V, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('gtt.pickle', 'wb') as handle:\n",
    "    pickle.dump(Gtt, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     unserialized_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def computeTheta(C_t):\n",
    "    vertex_cluster_contribution_sum = np.sum(C_t, axis = 0)\n",
    "    theta = min(vertex_cluster_contribution_sum)\n",
    "    return theta, vertex_cluster_contribution_sum\n",
    "\n",
    "def computeObjectiveFunction(C, L, V, CN_sim, G):\n",
    "    k_type = len(C)\n",
    "    first_term, second_term = 0, 0\n",
    "    for type_ in range(k_type):\n",
    "        sim_t = CN_sim[type_]\n",
    "        C_t = C[type_]\n",
    "        n_t = len(sim_t)#n_t: number of vertices in the type\n",
    "\n",
    "        for i in range(n_t):\n",
    "            for j in range(i):\n",
    "                first_term += sim_t[i][j]*np.sum((C_t[i] - C_t[j])**2)\n",
    "\n",
    "    for t in range(k_type):\n",
    "        for t_dash in range(t+1,k_type):\n",
    "            G_t_t_dash = Gtt[(t,t_dash)]\n",
    "            temp1 = np.matmul(L[(t, t_dash)]['adj_matrix'],C[t_dash].transpose())\n",
    "            temp2 = np.matmul(C[t], temp1)\n",
    "\n",
    "            second_term += np.sum((G_t_t_dash - temp2)**2)\n",
    "\n",
    "    objective = first_term + second_term\n",
    "    return objective\n",
    "\n",
    "def removeSuperNodeFromL(L, t_type, supernode, index):\n",
    "    L_temp = copy.deepcopy(L)\n",
    "    for types, superlinks in L_temp.items():\n",
    "        if types[0] > t_type:\n",
    "            break\n",
    "        elif types[0] == t_type:\n",
    "            superlinks['adj_matrix'] = np.delete(superlinks['adj_matrix'], index , 0)\n",
    "            #superlinks[types[0]].remove(supernode)\n",
    "        \n",
    "        elif types[1] == t_type:\n",
    "            superlinks['adj_matrix'] = np.delete(superlinks['adj_matrix'], index , 1)\n",
    "            #superlinks[types[1]].remove(supernode)\n",
    "\n",
    "    return L_temp\n",
    "\n",
    "def getOptimalSuperNode(G, SG, S, C, L, V, CN_sim):\n",
    "    VC = []\n",
    "    for i in range(0,len(C)):\n",
    "        theta, vertex_cluster_contribution_sum = computeTheta(C[i])\n",
    "        #print(\"theta:\",theta)\n",
    "        #VC.append(vertex_cluster_contribution_sum)\n",
    "        index = np.argmin(vertex_cluster_contribution_sum)\n",
    "        name_node = S[i]['name'][index]\n",
    "        C[i] = np.delete(C[i],index,1)\n",
    "        L = removeSuperNodeFromL(L,i,name_node,index)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #SG, S = createSummaryGraph(G, C, V, k_type)\n",
    "    print(\"Time taken to update the summary graph:\", (time.time()-start_time)/60)\n",
    "    return C, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to update the summary graph: 1.5894571940104166e-08\n",
      "2762.7663220598474 0.7159092596283616\n",
      "Time taken to update the Summary Graph: 8.502154036362965\n",
      "Super Nodes remaining:  66 88\n",
      "Time taken to calculate the objective function: 4.929713102181752\n",
      "Time taken to update the summary graph: 0.0\n",
      "1645.3109661475683 0.8312959515498803\n",
      "Time taken to update the Summary Graph: 8.690619130929312\n",
      "Super Nodes remaining:  65 87\n",
      "Time taken to calculate the objective function: 6.260622084140778\n",
      "Time taken to update the summary graph: 1.9868214925130207e-08\n",
      "935.2596847817188 0.829565095029573\n",
      "Time taken to update the Summary Graph: 8.666890414555867\n",
      "Super Nodes remaining:  64 86\n",
      "Time taken to calculate the objective function: 4.927519047260285\n",
      "Time taken to update the summary graph: 0.0\n",
      "526.3652487697968 0.6210521312110531\n",
      "Time taken to update the Summary Graph: 8.59345358212789\n",
      "Super Nodes remaining:  63 85\n",
      "Time taken to calculate the objective function: 4.941975772380829\n",
      "Time taken to update the summary graph: 1.5894571940104166e-08\n",
      "309.16906899566993 0.8000938646210851\n",
      "Time taken to update the Summary Graph: 40.45996598402659\n",
      "Super Nodes remaining:  62 84\n",
      "Time taken to calculate the objective function: 4.839087883631389\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "        # Step 2: Call Search(G,S(G))\n",
    "        C, L = getOptimalSuperNode(G, SG, S, C, L, V, CN_sim)\n",
    "        \n",
    "        # Step 3: update C and L\n",
    "        C_values=[]\n",
    "        change_C=[]\n",
    "        L_values=[]\n",
    "        change_L=[]\n",
    "        for j in range(1):\n",
    "            C_old = copy.deepcopy(C)\n",
    "            C = updateC(G, V, C, L, CN_sim, D)\n",
    "            L_old = copy.deepcopy(L)\n",
    "            L = updateL(G, V, C, L)\n",
    "            sum_C=0\n",
    "            sum_L=0\n",
    "            for i in range(0,len(C)):\n",
    "                sum_C+=np.sum(abs(C[i]-C_old[i]))\n",
    "            for tt_dash in L:\n",
    "                sum_L+=np.sum(abs(L[tt_dash]['adj_matrix']-L_old[tt_dash]['adj_matrix']))\n",
    "            \n",
    "            print(sum_C,sum_L)\n",
    "            change_C.append(sum_C)\n",
    "            change_L.append(sum_L)\n",
    "            C_values.append(C)\n",
    "            L_values.append(L)\n",
    "        \n",
    "        index = change_C.index(min(change_C))\n",
    "        C = C_values[index]\n",
    "        index = change_L.index(min(change_L))\n",
    "        L = L_values[index]\n",
    "        \n",
    "        # Construct the new summary graph S(G)\n",
    "        indices_to_keep = []\n",
    "        t = list(set(np.argmax(C[0], axis=1)))\n",
    "        indices_to_keep.append(t)\n",
    "        C[0] = C[0][:,t]\n",
    "        t = list(set(np.argmax(C[1], axis=1)))\n",
    "        indices_to_keep.append(t)\n",
    "        C[1] = C[1][:,t]\n",
    "        #update the Ltt\n",
    "        #hard-coding again -----\n",
    "        temp_L = copy.deepcopy(L[(0,1)]['adj_matrix'])\n",
    "        temp_L = temp_L[indices_to_keep[0],:]\n",
    "        temp_L = temp_L[:,indices_to_keep[1]]\n",
    "        \n",
    "        L[(0,1)]['adj_matrix'] = temp_L\n",
    "        start_time = time.time()\n",
    "        SG, S = createSummaryGraph(G, C, V, k_type)\n",
    "        print(\"Time taken to update the Summary Graph:\", (time.time()-start_time)/60)\n",
    "        print(\"Super Nodes remaining: \", len(indices_to_keep[0]), len(indices_to_keep[1]))\n",
    "        # Calculate the new objective function\n",
    "        start_time = time.time()\n",
    "        final_objective = computeObjectiveFunction(C, L, V, CN_sim, G)\n",
    "        print(\"Time taken to calculate the objective function:\",(time.time()-start_time)/60)\n",
    "        \n",
    "#         if final_objective<initial_objective:\n",
    "#             SG_final = copy.deepcopy(SG)\n",
    "#             C_final = copy.deepcopy(C)\n",
    "#             S_final = copy.deepcopy(S)\n",
    "#             L_final = copy.deepcopy(L)\n",
    "#             initial_objective = final_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "\n",
    "def temp_func(l):\n",
    "    l[1] = \"lisa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(set(np.argmax(C[1], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[2,3,4],[4,5,6]])\n",
    "x = [0,1]\n",
    "y = [0,1]\n",
    "\n",
    "a[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(np.argmax(C[1], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_super_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
